# ‚úÖ ROZWIƒÑZANIE: Azure Speech Services - Diaryzacja (Conversation Transcription)

## üî¥ PROBLEM

```
ErrorCode=ServiceError: WebSocket upgrade failed: Internal service error (404)
Error Details: Failed with HTTP 404 Resource Not Found
```

### Dlaczego testowy kod dzia≈Ça, a nasza aplikacja nie?

| Aspekt | Testowy kod ‚úÖ | Nasza aplikacja ‚ùå |
|--------|----------------|-------------------|
| **Recognizer** | `SpeechRecognizer` | `ConversationTranscriber` |
| **Diaryzacja** | NIE (brak rozpoznawania m√≥wc√≥w) | TAK (rozpoznawanie m√≥wc√≥w) |
| **Resource** | Multi-service Cognitive Services | **WYMAGA dedykowanego Speech Services** |
| **Klucz** | Dzia≈Ça | **NIE DZIA≈ÅA** (404 b≈ÇƒÖd) |

**Wniosek:** `ConversationTranscriber` (diaryzacja) **WYMAGA dedykowanego Speech Services resource**, nie mo≈ºe u≈ºywaƒá multi-service Cognitive Services!

---

## ‚úÖ ROZWIƒÑZANIE

### **Opcja 1: Utw√≥rz dedykowany Speech Services resource (ZALECANE)**

#### **Krok 1: Azure Portal - Utw√≥rz Speech Services**

1. Przejd≈∫ do: https://portal.azure.com
2. Kliknij: **"Create a resource"**
3. Szukaj: **"Speech Services"** ‚Üê WA≈ªNE: NIE "Cognitive Services"!
4. Wybierz: **"Speech Services"** (ikona z mikrofonem)
5. Kliknij: **"Create"**

#### **Krok 2: Konfiguracja**

```
Subscription: Azure for startups
Resource Group: aits-azuere-ai-services-rg (lub utw√≥rz nowy)
Region: West Europe
Name: aits-speech-diarization
Pricing Tier: Standard S0 (dla diaryzacji w produkcji)
             lub Free F0 (do test√≥w, mo≈ºe mieƒá ograniczenia)
```

6. Kliknij: **"Review + Create"** ‚Üí **"Create"**
7. Poczekaj na utworzenie (1-2 minuty)

#### **Krok 3: Pobierz klucz**

1. Po utworzeniu przejd≈∫ do resource
2. W menu po lewej kliknij: **"Keys and Endpoint"**
3. Skopiuj:
   - **KEY 1**: `[TW√ìJ_NOWY_KLUCZ]`
   - **Location/Region**: `westeurope`

#### **Krok 4: Zaktualizuj appsettings.Development.json**

```json
"AzureSpeech": {
  "SubscriptionKey": "[WKLEJ_TUTAJ_NOWY_KLUCZ_Z_KROKU_3]",
  "Region": "westeurope",
  "Language": "pl-PL",
  "MaxSpeakerCount": 3
}
```

**WA≈ªNE:** 
- ‚ùå **NIE DODAWAJ** pola `Endpoint`
- ‚úÖ U≈ºywaj tylko `Region` i `SubscriptionKey`

#### **Krok 5: Przebuduj i uruchom**

```powershell
# W katalogu server
dotnet build AITS.Api/AITS.Api.csproj

# Uruchom API
$env:ASPNETCORE_ENVIRONMENT="Development"
dotnet run --project AITS.Api/AITS.Api.csproj
```

W logach powiniene≈õ zobaczyƒá:
```
info: AITS.Api.Services.AzureSpeechService[0]
      Korzystanie z regionu Azure Speech: westeurope

dbug: AITS.Api.Services.AzureSpeechService[0]
      Sesja Azure Speech rozpoczƒôta: SessionId=xxx

dbug: AITS.Api.Services.AzureSpeechService[0]
      Otrzymano wynik transkrypcji: Reason=RecognizedSpeech, Text=..., SpeakerId=Guest-1
```

---

### **Opcja 2: Wy≈ÇƒÖcz diaryzacjƒô (NIE ZALECANE)**

Je≈õli naprawdƒô nie potrzebujesz rozpoznawania m√≥wc√≥w (diaryzacji), mo≈ºesz zmieniƒá kod na `SpeechRecognizer`:

**W `AzureSpeechService.cs` zmie≈Ñ:**

```csharp
// BY≈ÅO (z diaryzacjƒÖ):
using var transcriber = new ConversationTranscriber(speechConfig, audioConfig);

// BƒòDZIE (bez diaryzacji):
using var recognizer = new SpeechRecognizer(speechConfig, audioConfig);
```

**ALE:** Stracisz rozpoznawanie m√≥wc√≥w (SpeakerId bƒôdzie zawsze pusty).

---

## üîç Weryfikacja rozwiƒÖzania

### **Test 1: Sprawd≈∫ typ resource w Azure Portal**

1. Przejd≈∫ do: https://portal.azure.com
2. Znajd≈∫ sw√≥j nowy Speech Services resource
3. Sprawd≈∫:
   - ‚úÖ **Kind:** powinno byƒá **"SpeechServices"**
   - ‚ùå **NIE:** "CognitiveServices"

### **Test 2: Przetestuj endpoint przez cURL**

```powershell
$key = "[TW√ìJ_NOWY_KLUCZ]"
$region = "westeurope"

# Test autoryzacji
curl -v -X POST "https://$region.stt.speech.microsoft.com/cognitiveservices/v1" `
  -H "Ocp-Apim-Subscription-Key: $key" `
  -H "Content-Type: application/ssml+xml" `
  -d "<speak version='1.0' xml:lang='pl-PL'><voice name='pl-PL-ZofiaNeural'>Test</voice></speak>"
```

**Oczekiwany wynik:**
- ‚úÖ Status: 200 OK
- ‚ùå Status: 401 ‚Üí Z≈Çy klucz
- ‚ùå Status: 404 ‚Üí Z≈Çy region lub typ resource

### **Test 3: Uruchom aplikacjƒô i testuj diaryzacjƒô**

1. Uruchom API i klienta
2. Rozpocznij nagrywanie na ≈ºywo
3. Powiedz co≈õ do mikrofonu
4. Sprawd≈∫ logi:

```
dbug: AITS.Api.Services.AzureSpeechService[0]
      Otrzymano wynik transkrypcji: Reason=RecognizedSpeech, Text=Dzie≈Ñ dobry, SpeakerId=Guest-1
```

**SpeakerId powinien byƒá:** `Guest-1`, `Guest-2`, itp. (nie pusty!)

---

## üìã Por√≥wnanie: Cognitive Services vs Speech Services

| Cecha | Multi-service Cognitive Services | Dedykowany Speech Services |
|-------|----------------------------------|----------------------------|
| **Endpoint** | `https://westeurope.api.cognitive.microsoft.com/` | Region-based (automatyczny) |
| **SpeechRecognizer** | ‚úÖ Dzia≈Ça | ‚úÖ Dzia≈Ça |
| **ConversationTranscriber** | ‚ùå **NIE DZIA≈ÅA (404)** | ‚úÖ **DZIA≈ÅA** |
| **Diaryzacja** | ‚ùå Nie wspierana | ‚úÖ Pe≈Çne wsparcie |
| **Pricing** | Multi-service bundle | Dedykowany dla Speech |

---

## üéØ Podsumowanie

### ‚úÖ **Co zrobiƒá:**
1. Utw√≥rz dedykowany **Speech Services** resource w Azure Portal
2. Skopiuj nowy klucz
3. Zaktualizuj `appsettings.Development.json` (tylko `SubscriptionKey` i `Region`, BEZ `Endpoint`)
4. Przebuduj i uruchom aplikacjƒô

### ‚ùå **Czego NIE robiƒá:**
- ‚ùå Nie u≈ºywaj multi-service Cognitive Services dla diaryzacji
- ‚ùå Nie dodawaj pola `Endpoint` do konfiguracji (u≈ºywaj tylko `Region`)
- ‚ùå Nie u≈ºywaj endpoint `https://westeurope.api.cognitive.microsoft.com/` dla ConversationTranscriber

---

## üìû Je≈õli nadal nie dzia≈Ça:

1. Sprawd≈∫ logi API (szukaj `ErrorCode=` i `ErrorDetails=`)
2. Sprawd≈∫ typ resource w Azure Portal (powinien byƒá "SpeechServices", nie "CognitiveServices")
3. Sprawd≈∫ czy region to `westeurope` (zgodny z Location w Azure Portal)
4. Upewnij siƒô, ≈ºe klucz jest z **dedykowanego Speech Services**, nie z Cognitive Services

**Z dedykowanym Speech Services resource diaryzacja bƒôdzie dzia≈Çaƒá! üéâ**


